目录：
chaper 1: 介绍机器学习
	机器学习 起源
	机器学习 使用与滥用
		机器学习 成功
			1. 识别电子邮件中不需要的垃圾邮件
			2. 针对目标广告客户行为的细分
			3. 天气行为和长期气候变化的预测
			4. 减少欺骗性的信用卡交易
			5. 风暴和自然灾害的财务损失的精算估计
			6. 预测普选结果
			7. 开发自动驾驶无人机和自动驾驶汽车的算法
			8. 优化家庭和办公楼的能源使用
			9. 最可能发生犯罪活动的地区的投影
			10. 发现与疾病有关的基因序列
			
			不管任务是什么，机器学习算法过程包括：①获取数据，②识别形成采取进一步行动的依据的模式。
			
		机器学习 局限性
			
		机器学习 伦理
			在获取或分析数据以避免违反法律，违反服务条款或数据使用。协议，滥用信任或侵犯客户或公众的隐私
	
	
	
	机器是如何学习
			1. 计算机科学家汤姆·M提出的机器学习的正式定义：只要机器能利用它的经验，它就能学习，这样，它的性能将在将来类似的经验基础上得到改善。
			虽然这个定义很直观，但是完全忽略了如何将经验转化为未来的行为，并且当然，学习永远都是说起来容易做起来难!
			人类学习的天赋与生俱来，但是计算机必须明确学习的条件。
			2. 无论是人学习者还是机器，基本的学习过程是相似的：
				1)数据存储（数据）  利用观测、内存、调用为进一步的推理提供一个事实基础。
				2)抽象（理解）  将存储的数据转换为更广泛的数据表象和概念。
				3)广义（推断） 利用抽象的数据来创建在新的环境中推动行动知识和推论。
				4)评价  提供一个反馈机制来衡量学习的效果，了解并告知潜在需要改进的地方。
			
		数据储存
			人类和计算机都使用数据存储作为更高级的推理的基础。
			在人类中，这包括一个大脑--在生物细胞网络中使用电化学信号来储存和处理对短期和长期观察的未来回忆。
			在计算机中，参与这一过程包含的硬件有，硬盘，闪存，内存结合中央处理单元（CPU）
		抽象
			为存储数据赋上有意义的值，发生在抽象过程中（原始数据具有更抽象的含义。）
			在机器的知识表示过程中，使用模型（显式描述数据中的模式）概括存储原始数据。
			有许多不同类型的模型，例如其中包括：
				1.Mathematical Equations 数理方程
				2.Relational diagrams such as trees and graphs  关系图，如树和图
				3.Logical if/else rules  逻辑if / else规则
				4.Groupings of data known as clusters 分组的数据被称为簇
			模型的选择通常不取决于机器，而是取决于学习任务和手头的数据。
			将模型拟合到数据集的过程称为训练。当使用模型训练后，数据被转化为一个抽象的形式来概括原始信息。
			你可能想知道为什么这一步被称为训练而不是学习。
				首先，请注意，学习过程并不以数据抽象结束;还必须对其训练进行归纳和评价。
				其次，训练更好的体现，人类教师以特定的方式训练机器学生理解数据。
				
																	
		归纳
		评估
	机器学习在实践中的应用
		任何机器学习算法都可以通过以下步骤进行部署:
			1. 数据收集：收集学习算法将使用的数据。数据需要合并成文本文件、表格或数据库。
			2. 数据探索和准备:机器学习的质量很大程度基于输入的数据质量。
				清理所谓的“混乱”数据，消除不必要的数据，记录符合学习者的预期输入的数据。
			3.模型训练：机器学习任务决定算法的选择，算法以模型的形式表示数据。
			4.模型评价：每个机器学习任务都是有偏倚的解决学习问题，那么评价模型算法优劣就很重要了。
			5.模型改进：有时可能需要切换到不同类型的模型，也可能需要用其他数据补充您的数据或者重复一、二步。
			
		输入数据类型
			1.每一行表示一个实例，每一列表示一个特征
			2.表示特征的数据类型有：数值变量、名义（分类）变量、有序变量（名义变量特例）、
							
		机器学习算法的类型
			1.预测模型：发现并建立目标（预测）特性之间关系的模型。预测模型不一定是用与预测未来事件，也可以预测过去发生的事情。例如可以通过孕妇今天的激素水平预测怀孕的日期。
				在交通高峰期，预测模型可以用来控制交通信号灯。
				1) 预测模型为有监督学习，监督不涉及人的参与。更准确的来说，就是给定数据集，通过监督学习算法找到通过特征值产生目标结果的一个函数（模型）。
					常用的监督机器学习任务是预测实例属于哪个分类。很容易想到潜在的用途--“分类器”。
					例子：
						预测电子邮件是否是垃圾邮件
						诊断病人是否患癌症
						预测足球队胜利或者失败
						预测贷款申请人会拖欠还款
					预测的目标特征是已知类属特征的，称为类，其被划分为等级，称水平。一个类有两个或多个水平，各水平间可以是有序或者无序的。由于分类在机器学习中被广泛应用，因此有很多分类算法，对不同的数据各自有着优势和劣势。	
				2) 有监督学习预测模型同样可以用来预测收入，实验数据，测试得分，物品计数。对数值目标的预测通常拟合线性回归模型。回归模型不仅仅适用数值模型。回归方法被广泛应用于预测，精确量化输入数据与目标之间的关联，确定的数量关系和不确定的相关关系。
			2.描述模型：一个描述性的模型用于从新的、有趣的方式总结数据。与预测目标的预测模型相反，在描述性模型中，没有单个特征比任何其他特征更重要。
				1) 由于没有感兴趣的目标，描述模型也叫无监督学习，尽管描述性模型的应用可能比较困难，但是在数据挖掘上用得很好。
					描述性建模任务称为“模式发现”，用来识别数据中有用的关联。模式发现经常被用于零售商交易数据中的购物篮分析。
					例如：
						零售商了解到泳裤通常在太阳镜的同时购买。
						同样可以用于检测欺诈行为的模式，筛选遗传缺陷，或识别犯罪活动的热点。
				2) 将数据集划分为同构组的描述性建模任务称为"聚类"。这有时被用于分割分析，识别具有相似行为或人口信息的个人组，从而可以针对特定受众定制广告活动。
					最后，一类称为元学习者的机器学习算法与特定的学习任务无关，而是专注于学习如何更有效地学习。这对于有挑战性的问题或预测算法的性能需要尽可能精确是有益的。
		数据与算法
			Model 								Learning task 				Chapter
			Supervised Learning Algorithms（监督学习算法）
			Nearest Neighbor（最近邻点插值法）  	  Classification 				3
			Naive Bayes（朴素贝叶斯				Classification 				4
			Decision Trees（决策树） 			 Classification 				5
			Classification Rule Learners		Classification 				5
			（分类规则学习者） 
			Linear Regression（线性回归） 		Numeric prediction 			6
			Regression Trees（回归树）			 Numeric prediction 			6
			Model Trees（模型树） 				 Numeric prediction 			6
			Neural Networks（类神经网络） 		   Dual use？					7
			Support Vector Machines				Dual use 					7
			（支持向量机） 
			Unsupervised Learning Algorithms（无监督学习算法）
			Association Rules（关联规则） 		Pattern detection 			8
			k-means clustering（k-均值聚类） 	Clustering 					     9
			Meta-Learning Algorithms（元学习算法）
			Bagging 							Dual use 					11
			Boosting 							Dual use 					11
			Random Forests（随机森林） 			Dual use 					11
			
			
			
	R语言的机器学习
		安装R包
		装载和卸载R包
	总结

chaper 2: 管理和理解数据
	R 数据结构
		向量
		因子
		列表	
		数据框
		矩阵和数组
	R 管理数据
		保存、加载和删除R数据结构
		从CSV文件导入和保存数据

	探索和理解数据
		探索数据结构
		探索数值变量
			集中趋势的测量—均值和中位数
			测量四分位数和五个数字摘要
			可视化数字变量-盒形图
			可视化数字变量-直方图
			理解数值数据——均匀分布和正态分布
			测量偏差-方差和标准偏差
		探索分类变量
			测量集中趋势-模式
		探索变量之间的关系
			可视化-散点图
			检查-双向交叉表
	总结

Chapter 3: 懒惰学习-使用最近邻分类
	
		例子：
			一种有趣的新型餐饮体验已经出现在世界各地的城市。顾客们在一个完全昏暗的餐厅里侍候侍者，
			他们只会用触觉和声音小心地绕过记忆路线。这些机构的魅力在于相信剥夺视觉感官输入会增强味觉和嗅觉，
			食物将以新的方式体验。每次咀嚼在发现厨师准备的口味的同时，也会带来一种神奇的感觉。
			你能想象一个用餐者如何体验看不见的食物吗？尝第一口后，感官就不知所措了。
			最主要的味道是什么？食物尝起来是香的还是甜的？和以前吃的东西味道相似吗？
			就我个人而言，我从一个稍加修改的谚语中想象出这一过程：如果它闻起来像鸭子，
			尝起来像鸭子，那么你很可能是在吃鸭子。
			----这说明了一种可以用于机器学习的思想，就像另一格言：“物以类聚，人以群分”(birds of a feather flock together)。
			换句话说，相同的事物很可能具有相似的特性。机器学习使用这个原理对数据进行分类，将数据放在与相似的或最近的“邻居”相同的类别中。
			将学到：
				1.最近邻分类器的关键概念及其为什么被认为是“懒惰”的学习者
				2.使用距离测量两个实例的相似度方法
				3.应用一种流行的最近邻分类器称为K-NN
			我们的第一个任务将是理解K-NN方法，把它用于解决长期运行的烹饪辩论。
	理解最近邻分类
		应用领域：
			1.计算机视觉应用，包括静止图像和视频中的光学字符识别和面部识别
			2.预测一个人是否会欣赏推荐的电影或音乐
			3.识别遗传学数据中的模式，用来检测特定的蛋白质或疾病
			一般来说，最近邻分类器非常适合于分类任务。其中特征和目标类之间的关系是多方面的，复杂的，或者是非常难以理解的，但是相似类类型中的个体往往是比较均匀的。
			另一种说法是，如果一个概念很难定义，但是当你看到它时你能理解，那么最近邻分类可能是合适的。另一方面，如果数据中有很多干扰数据，导致组之间没有明显的区别，最近邻算法可能难以识别类边界。  
		K-NN算法
			最近邻分类方法--K-近邻算法（K-NN），虽然这可能是最简单的机器学习算法之一，但它仍然被广泛使用。
			优势：
				1.简单、高效
				2.对基础数据分布不作任何假设
				3.训练阶段快速
			劣势：
				1.不生成模型，对于理解特征如何与类相关有一定理解
				2.需要选择合适的K值
				3.分类阶段缓慢
				4.名义特征和缺失数据需要额外的处理
			字母k是一个变量，表示可以使用的最近邻居数量。设定k值后，K-NN算法需要一个训练数据集，由被分类为若干类别（名义变量标记）的样本组成。
				然后，对于测试数据集中的每个未标记的记录，K-NN识别训练数据中的k个相似记录，将未标记的测试实例分配到近邻的类。			
				为了说明这个过程，让我们再回顾一下介绍中的闭眼品尝体验：
					假设在吃神秘餐之前，我们已经创建了一个数据集，在其中我们记录了我们以前品尝过的一些食料。使问题简单化，我们只评价每种成分的两种特征。
					第一个特征值表示成分脆硬的程度：数值为1-10
					第二个特征值表示成分甜味程度：1-10
					第三个表示为成分的类型：水果、蔬菜、蛋白质
					成分				甜度				脆硬度				食物类型
					apple			10					9				fruit
					bacon			1					4				protein
					banana			10					1				fruit
					carrot			7					10				vegetable
					celery			3					10				vegetable
					cheese			1					1				protein
				K-NN算法将特征视为多维特征空间中的坐标。由于我们的数据集仅包含两个特征，特征空间是二维的。	
				假设在构造这个数据集之后，我们决定用它来解决一个古老的问题：番茄是水果还是蔬菜？
				
			使用距离检测相似度
			选择合适的K
			准备K-NN用的数据
		为什么K-NN算法是懒惰的？
	实例：用K-NN算法诊断乳腺癌
		第1步-收集数据
		第2步-探索和准备数据
			转换-归一化数值数据
			数据准备-创建培训和测试数据集
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
			变换-Z评分标准化
			测试K的替代值
	总结

Chapter 4:概率学习-使用朴素贝叶斯分类
	理解Naive Bayes
		贝叶斯方法的基本概念
			理解概率
			理解联合概率
			用贝叶斯定理计算条件概率
		朴素贝叶斯算法
			朴素贝叶斯分类
			拉普拉斯估计量
			使用朴素贝叶斯的数字特征
	示例-使用朴素贝叶斯算法过滤手机垃圾	
		第1步-收集数据
		第2步-探索和准备数据
			数据准备-清理和标准化文本数据
			数据准备-将文本文档分割成单词
			数据准备-创建训练和测试数据集
			可视化文本数据-单词云
			数据准备-创建频繁词的指示符特征
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
	总结

Chapter 5: 分而治之-使用决策树和规则分类
	理解决策树
		分而治之
		C5.0决策树算法
			选择最佳分割
			修剪决策树
	实例：使用C5.0决策树识别风险银行贷款
		第1步-收集数据
		第2步-探索和准备数据
			数据准备-创建随机训练和测试数据集
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
			提高决策树的精度
			犯错比别人更昂贵
	理解分类规则
		分而治之
		1R算法
		撕裂器算法
		决策树规则
		什么使决策树和规则贪婪？
	实例：用规则学习识别毒蕈
		第1步-收集数据
		第2步-探索和准备数据
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
	总结

Chapter 6: 预测数字数据-回归方法
	理解回归
		简单线性回归
		普通最小二乘估计
		相关性
		多元线性回归
	实例：用线性回归预测医疗费用
		第1步-收集数据
		第2步-探索和准备数据
			探索特征之间的关系-相关矩阵
			可视化特征之间的关系—散点图矩阵
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
			模型规范-增加非线性关系
			转换-将数值变量转换为二进制指示符
			模型规范-增加交互作用
			把它们结合在一起——一个改进的回归模型
	回归树与模型树的理解
		向树中添加回归
	示例-使用回归树与模型树估计葡萄酒的质量
		第1步-收集数据
		第2步-探索和准备数据
		第3步—训练数据模型
			可视化决策树
		第4步-评估模型性能
			用平均绝对误差测量性能
		第5步-提高模型性能
	总结

Chapter 7: 黑箱方法-神经网络和支持向量机
	理解神经网络
		从生物到人工神经元
		激活函数
		网络拓扑
			层数
			信息传播的方向
			每个层中的节点数量
		基于BP(backpropagation)的神经网络训练
	实例:ANNs混凝土强度模型
		第1步-收集数据
		第2步-探索和准备数据
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
	理解支持向量机
		超平面分类
			线性可分离数据的情形
			非线性可分离数据的情形	
		核在非线性空间中的应用
	示例-用SVMs执行OCR
	第1步-收集数据
	第2步-探索和准备数据
	第3步—训练数据模型
	第4步-评估模型性能
	第5步-提高模型性能

Chapter 8: 寻找模式-使用关联规则分析购物篮
	理解关联规则
		关联规则学习的Apriori算法
		测量规则兴趣-支持和信心
		用Apriori原理构造一套规则
	示例-使用关联规则识别经常购买的食品杂货
		第1步-收集数据
		第2步-探索和准备数据
			数据准备—为事务数据创建稀疏矩阵
			可视化项目支持-项目频率图
			可视化事务数据—绘制稀疏矩阵
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
			关联规则集的排序
			利用关联规则子集
			将关联规则保存到文件或数据框
	总结

Chapter 9:数据分组-用k-均值聚类
	理解聚类
		聚类作为机器学习的一个任务
		k-均值聚类算法
			使用距离分配和更新簇
			选择合适的簇数
	实例：使用k-均值聚类寻找青少年市场细分
		第1步-收集数据
		第2步-探索和准备数据
			数据准备-虚拟编码缺失值
			数据准备-填充缺失值
		第3步—训练数据模型
		第4步-评估模型性能
		第5步-提高模型性能
	总结

Chapter 10:模型性能评估
	分类性能测量
		在R中使用分类预测数据
		混淆矩阵的进一步研究
		用混淆矩阵测量性能
		超越准确性-其他性能指标
			Kappa统计量
			敏感性和特异性
			精度与召回
			F测度
		可视化性能权衡
			ROC曲线
	估计未来性能
		截留法
			交叉验证
			自举抽样
	总结

Chapter 11: 提高模型性能
	调整股票模型以获得更好的业绩
		使用插入符号进行自动参数整定
			创建一个简单的调谐模型
			定制调谐过程
	利用元学习提高模型性能
	理解？合奏？
	套袋
	助推
	随机森林
		随机森林训练
		随机森林绩效评价
	总结

Chapter 12: 专业的机器学习主题
	使用专有文件和数据库
		阅读和写作微软Excel，SAS，SPSS和STATA文件
		SQL数据库中的数据查询
	使用在线数据和服务
		下载网页的完整文本
		从网页中抓取数据
			解析XML文档
			从Web API解析JSON
	使用特定于域的数据
		生物信息学数据分析
		网络数据的分析与可视化
	提高R的性能
		管理非常大的数据集
			用dplyr实现表格数据结构的通用化
			用data.table实现快数据框快速读入
			用FF创建基于磁盘的数据框
			使用大容量存储器的海量矩阵
		利用并行计算加快学习
			执行时间测量
			使用R包：multicore和snow并行计算
			利用foreach 和 doParallel并行计算
			利用MapReduce和Hadoop的并行云计算
		GPU计算
		部署优化学习算法
			用biglm包建立大回归模型
			用bigrf包扩展更大、更快的随机森林
			用caret包并行的训练和评估模型
	